{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ac666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from newsapi import NewsApiClient\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"=== 1. NewsAPI Initialization ===\")\n",
    "newsapi = NewsApiClient(api_key='fe27f943772a4235a29f751edabae735') \n",
    "\n",
    "# Date range setup (last 30 days)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "try:\n",
    "    # Fetch Bitcoin news\n",
    "    print(\"\\n=== 1. Fetching News Articles with Pagination ===\")\n",
    "    articles = []\n",
    "    max_pages = 5  # Try up to 5 pages (100 per page = max 500 if needed)\n",
    "    for page in range(1, max_pages + 1):\n",
    "        try:\n",
    "            response = newsapi.get_everything(\n",
    "                q='Bitcoin OR BTC',\n",
    "                language='en',\n",
    "                from_param=start_date.strftime('%Y-%m-%d'),\n",
    "                to=end_date.strftime('%Y-%m-%d'),\n",
    "                sort_by='publishedAt',\n",
    "                page_size=100,\n",
    "                page=page\n",
    "            )\n",
    "            page_articles = response.get('articles', [])\n",
    "            if not page_articles: # if no articles left stop\n",
    "                break \n",
    "            articles.extend(page_articles)\n",
    "        except Exception as e:\n",
    "            print(f\"Page {page} fetch failed: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    # Make into DataFrame and clean\n",
    "    news_df = pd.DataFrame(articles)\n",
    "    news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt']).dt.tz_localize(None)\n",
    "    news_df = news_df[['title', 'publishedAt']].drop_duplicates().dropna()\n",
    "\n",
    "    print(f\"Retrieved {len(news_df)} news articles across {page} page(s). Sample:\")\n",
    "    display(news_df.head(3))\n",
    "\n",
    "    # Limit to 100 if too many\n",
    "    news_df = news_df.head(100)\n",
    "\n",
    "    # Basic cleaning\n",
    "    news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt']).dt.tz_localize(None)\n",
    "    news_df = news_df[['title', 'publishedAt']].drop_duplicates()\n",
    "    \n",
    "    print(f\"Retrieved {len(news_df)} news articles. Sample:\")\n",
    "    display(news_df.head(2))\n",
    "    \n",
    "except Exception as e:\n",
    "    test_news = [\n",
    "        \"Bitcoin soars to $50,000 as institutional investors flock in\",\n",
    "        \"SEC delays decision on Bitcoin ETF, causing market panic\"\n",
    "    ]\n",
    "    news_df = pd.DataFrame({\n",
    "        'title': test_news,\n",
    "        'publishedAt': [datetime.now() - timedelta(days=x) for x in range(2)]\n",
    "    })\n",
    "    print(\"Using test data instead:\")\n",
    "    display(news_df)\n",
    "\n",
    "#sentiment analysis \n",
    "print(\"\\n=== 2. Sentiment Analysis Setup ===\")\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "try:\n",
    "    # Initialize FinBERT\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    finbert = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=\"ProsusAI/finbert\",\n",
    "        return_all_scores=True,\n",
    "        device=device,\n",
    "        truncation=True\n",
    "    )\n",
    "    print(f\"FinBERT loaded on {'GPU' if device == 0 else 'CPU'}\")\n",
    "    \n",
    "    # Sentiment extraction function\n",
    "    def get_sentiment(text):\n",
    "        try:\n",
    "            results = finbert(text[:512])[0]  # Truncate long texts\n",
    "            return {\n",
    "                'sent_pos': next(r['score'] for r in results if r['label'] == 'positive'),\n",
    "                'sent_neg': next(r['score'] for r in results if r['label'] == 'negative'),\n",
    "                'sent_neutral': next(r['score'] for r in results if r['label'] == 'neutral')\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing: '{text[:30]}...' - {str(e)}\")\n",
    "            return {'sent_pos': 0, 'sent_neg': 0, 'sent_neutral': 1}\n",
    "\n",
    "    # Process with progress bar\n",
    "    print(\"\\n=== 3. Processing Headlines ===\")\n",
    "    tqdm.pandas(desc=\"Analyzing\")\n",
    "    sentiment_df = pd.DataFrame(news_df['title'].progress_apply(get_sentiment).tolist())\n",
    "    enhanced_news = pd.concat([news_df, pd.DataFrame(sentiment_df)], axis=1)\n",
    "    \n",
    "    # VALIDATION BEFORE SAVING\n",
    "    print(\"\\n=== 4. Data Validation ===\")\n",
    "    # Ensure all sentiment columns are numeric\n",
    "    for col in ['sent_pos', 'sent_neg', 'sent_neutral']:\n",
    "        enhanced_news[col] = pd.to_numeric(enhanced_news[col], errors='coerce')\n",
    "        if enhanced_news[col].isnull().any():\n",
    "            print(f\"⚠️ Found {enhanced_news[col].isnull().sum()} null values in {col} - filling with 0\")\n",
    "            enhanced_news[col] = enhanced_news[col].fillna(0)\n",
    "    \n",
    "    text_in_sentiment = enhanced_news[\n",
    "        enhanced_news[['sent_pos', 'sent_neg', 'sent_neutral']]\n",
    "        .applymap(lambda x: isinstance(x, str))\n",
    "        .any(axis=1)\n",
    "    ]\n",
    "    if not text_in_sentiment.empty:\n",
    "        print(\" Found text\")\n",
    "        display(text_in_sentiment.head())\n",
    "        raise ValueError(\"Text values found in sentiment columns\")\n",
    "    \n",
    "    enhanced_news.to_csv(\n",
    "        'news_with_sentiment.csv',\n",
    "        index=False,\n",
    "        float_format='%.15f'  \n",
    "    )\n",
    "    print(f\"\\n Saved {len(enhanced_news)} records to 'news_with_sentiment.csv'\")\n",
    "    \n",
    "    # Verify saved file can be loaded correctly\n",
    "    test_load = pd.read_csv('news_with_sentiment.csv')\n",
    "    print(\"\\n=== 5. File Verification ===\")\n",
    "    print(\"Loaded data types:\")\n",
    "    print(test_load.dtypes)\n",
    "    print(\"\\nSample from saved file:\")\n",
    "    display(test_load[['title', 'sent_pos', 'sent_neg', 'sent_neutral']].head(3))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" error: {str(e)}\")\n",
    "    if 'enhanced_news' in locals():\n",
    "        print(\"\\nCurrent data sample:\")\n",
    "        display(enhanced_news.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
