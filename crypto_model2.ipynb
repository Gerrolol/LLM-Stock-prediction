{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d54b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (2.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Downloading xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/150.0 MB 4.2 MB/s eta 0:00:36\n",
      "   ---------------------------------------- 1.3/150.0 MB 4.0 MB/s eta 0:00:38\n",
      "    --------------------------------------- 2.4/150.0 MB 4.2 MB/s eta 0:00:36\n",
      "    --------------------------------------- 3.1/150.0 MB 4.3 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 4.2/150.0 MB 4.4 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 4.7/150.0 MB 4.1 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 5.8/150.0 MB 4.2 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 6.8/150.0 MB 4.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 7.9/150.0 MB 4.4 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 8.7/150.0 MB 4.5 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 9.4/150.0 MB 4.3 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 10.5/150.0 MB 4.4 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 11.3/150.0 MB 4.4 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 12.3/150.0 MB 4.4 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 13.4/150.0 MB 4.5 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 14.4/150.0 MB 4.5 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 15.5/150.0 MB 4.5 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 16.5/150.0 MB 4.6 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 17.6/150.0 MB 4.6 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 18.6/150.0 MB 4.6 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 19.7/150.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 20.7/150.0 MB 4.7 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 21.8/150.0 MB 4.7 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 22.8/150.0 MB 4.7 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 23.9/150.0 MB 4.7 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 24.9/150.0 MB 4.8 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 26.0/150.0 MB 4.8 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 27.0/150.0 MB 4.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 28.0/150.0 MB 4.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 29.1/150.0 MB 4.8 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 30.1/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 31.2/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 32.2/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 32.8/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 33.8/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 34.9/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 36.2/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 37.0/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 38.0/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 38.5/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 39.6/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 40.6/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 41.7/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 42.7/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 43.8/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 44.8/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 45.9/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 46.9/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 48.0/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 49.0/150.0 MB 4.8 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 50.1/150.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 50.9/150.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 52.2/150.0 MB 4.9 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 53.2/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 54.3/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 55.3/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 56.4/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 57.4/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 58.5/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 59.5/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 60.6/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 61.6/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 62.7/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 64.0/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 65.0/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 66.1/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 67.1/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 68.2/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 69.2/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 70.3/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 71.3/150.0 MB 4.9 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 72.1/150.0 MB 4.9 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 73.1/150.0 MB 4.9 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 74.2/150.0 MB 4.9 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 75.2/150.0 MB 4.9 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 76.3/150.0 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 77.3/150.0 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 78.4/150.0 MB 4.9 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 79.7/150.0 MB 5.0 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 80.7/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 81.8/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 82.6/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 83.6/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 84.7/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 85.7/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 86.8/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 87.8/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 88.9/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 89.9/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 91.0/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 92.0/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 93.1/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 94.1/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 95.2/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 96.2/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 97.0/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 98.0/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 99.1/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 100.1/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 101.2/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 102.2/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 103.3/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 104.3/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 105.4/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 106.4/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 107.5/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 108.5/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 109.6/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 110.9/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 111.7/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 112.7/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 113.8/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 114.6/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 115.6/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 116.7/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 117.7/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 118.5/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 119.5/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 120.3/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 121.4/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 122.7/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 123.7/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 124.8/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 125.8/150.0 MB 5.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 126.9/150.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 127.9/150.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 129.0/150.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 129.5/150.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 130.5/150.0 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 131.6/150.0 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 132.6/150.0 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 134.0/150.0 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 135.0/150.0 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 136.1/150.0 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 137.1/150.0 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 138.1/150.0 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 139.2/150.0 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 140.2/150.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.3/150.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 142.3/150.0 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 143.4/150.0 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 144.4/150.0 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 145.5/150.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  146.5/150.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  147.6/150.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.4/150.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.4/150.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.0/150.0 MB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ta\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from binance.client import Client\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# load in tha data\n",
    "def get_price_data(symbol='BTCUSDT', days=360):\n",
    "    \"\"\"Fetch price data with caching and validation\"\"\"\n",
    "    cache_file = 'price_data.csv'\n",
    "    try:\n",
    "        if os.path.exists(cache_file):\n",
    "            df = pd.read_csv(cache_file)\n",
    "            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "            df = df.dropna(subset=['Date'])\n",
    "            return df\n",
    "        \n",
    "        print(f\"Downloading {days} days of {symbol} data...\")\n",
    "        client = Client()\n",
    "        klines = client.get_historical_klines(\n",
    "            symbol=symbol,\n",
    "            interval=Client.KLINE_INTERVAL_1DAY,\n",
    "            limit=days\n",
    "        )\n",
    "        \n",
    "        df = pd.DataFrame(klines, columns=[\n",
    "            'Open time', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "            'Close time', 'Quote volume', 'Trades',\n",
    "            'Taker buy volume', 'Taker quote volume', 'Ignore'\n",
    "        ])\n",
    "        \n",
    "        df['Date'] = pd.to_datetime(df['Open time'], unit='ms').dt.normalize()\n",
    "        numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        df[numeric_cols] = df[numeric_cols].astype(float)\n",
    "        df = df[['Date'] + numeric_cols]\n",
    "        df.to_csv(cache_file, index=False)\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Price data error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_sentiment_data():\n",
    "    \"\"\"Load and validate sentiment data\"\"\"\n",
    "    if not os.path.exists('news_with_sentiment.csv'):\n",
    "        raise FileNotFoundError(\"Sentiment data not found. Run sentiment analysis first.\")\n",
    "    \n",
    "    df = pd.read_csv('news_with_sentiment.csv')\n",
    "    \n",
    "    for col in ['sent_pos', 'sent_neg', 'sent_neutral']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['publishedAt'], errors='coerce')\n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df['date'] = df['date'].dt.normalize()\n",
    "    \n",
    "    if len(df) < initial_count:\n",
    "        print(f\"Removed {initial_count - len(df)} rows with invalid dates\")\n",
    "    print(f\"Loaded {len(df)} sentiment records from {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "    return df\n",
    "\n",
    "#feature engineering\n",
    "def create_features(price_df, sentiment_df):\n",
    "    try:\n",
    "        price_df['Date'] = pd.to_datetime(price_df['Date'], errors='coerce').dt.normalize()\n",
    "        price_df = price_df.dropna(subset=['Date'])\n",
    "\n",
    "        print(\"\\n=== MERGE DEBUG ===\")\n",
    "        print(f\"Price dates: {price_df['Date'].min()} to {price_df['Date'].max()}\")\n",
    "        print(f\"Sentiment dates: {sentiment_df['date'].min()} to {sentiment_df['date'].max()}\")\n",
    "        \n",
    "        merged = pd.merge_asof(\n",
    "            price_df.sort_values('Date'),\n",
    "            sentiment_df.sort_values('date'),\n",
    "            left_on='Date',\n",
    "            right_on='date',\n",
    "            direction='forward',\n",
    "            tolerance=pd.Timedelta('60d')\n",
    "        )\n",
    "        print(\"\\n=== MERGED COLUMNS ===\")\n",
    "        print(merged.columns.tolist())\n",
    "        \n",
    "        print(\"\\n=== SENTIMENT VALUES IN MERGED DATA ===\")\n",
    "        print(merged[['Date', 'sent_pos', 'sent_neg', 'sent_neutral']].head())\n",
    "                \n",
    "        for col in ['sent_pos', 'sent_neg', 'sent_neutral']:\n",
    "            merged[col] = merged[col].fillna(0)\n",
    "        \n",
    "        # Technical indicators\n",
    "        merged['RSI_14'] = ta.momentum.RSIIndicator(merged['Close'], window=14).rsi()\n",
    "        merged['MACD'] = ta.trend.MACD(merged['Close']).macd()\n",
    "        merged['Volume_Spike'] = merged['Volume'] / merged['Volume'].rolling(5).mean() - 1\n",
    "        merged['ATR'] = ta.volatility.AverageTrueRange(\n",
    "            merged['High'], merged['Low'], merged['Close'], window=14\n",
    "        ).average_true_range()\n",
    "        \n",
    "        # Target: 1 if next day's return is positive, 0 otherwise\n",
    "        merged['Target'] = (merged['Close'].shift(-1) > merged['Close']).astype(int)\n",
    "        \n",
    "        return merged.dropna()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Feature engineering failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "#training/bcaktesting\n",
    "def walk_forward_train(features_df, initial_train_size=100, retrain_every=30):\n",
    "    \"\"\"Walk-forward training with accuracy tracking\"\"\"\n",
    "    if len(features_df) < initial_train_size + retrain_every:\n",
    "        raise ValueError(f\"Need at least {initial_train_size + retrain_every} samples, got {len(features_df)}\")\n",
    "    \n",
    "    # Define all possible features\n",
    "    all_feature_cols = ['RSI_14', 'MACD', 'Volume_Spike', 'sent_pos', 'sent_neg', 'sent_neutral', 'ATR']\n",
    "    \n",
    "    # Select only features that exist in the dataframe\n",
    "    feature_cols = [col for col in all_feature_cols if col in features_df.columns]\n",
    "    \n",
    "    results = []\n",
    "    models = []\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for i in range(initial_train_size, len(features_df), retrain_every):\n",
    "        train = features_df.iloc[max(0, i-initial_train_size):i]\n",
    "        test = features_df.iloc[i:min(i+retrain_every, len(features_df))]\n",
    "        \n",
    "        if len(test) == 0 or train['Target'].nunique() < 2:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Feature scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(train[feature_cols])\n",
    "            X_test = scaler.transform(test[feature_cols])\n",
    "            y_train = train['Target']\n",
    "            y_test = test['Target']\n",
    "            \n",
    "            # Model training\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=150,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                eval_metric=['error', 'logloss']\n",
    "            )\n",
    "            model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "            \n",
    "            # Predictions\n",
    "            test_preds = model.predict(X_test)\n",
    "            test_probs = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Store results\n",
    "            test_results = test[['Date', 'Close']].copy()\n",
    "            test_results['Prediction'] = test_preds\n",
    "            test_results['Probability'] = test_probs\n",
    "            test_results['Actual'] = y_test.values\n",
    "            test_results['Next_Close'] = features_df['Close'].shift(-1).iloc[i:i+len(test)].values\n",
    "            results.append(test_results)\n",
    "            models.append(model)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "            accuracy_scores.append(accuracy_score(y_test, test_preds))\n",
    "            precision_scores.append(precision_score(y_test, test_preds))\n",
    "            recall_scores.append(recall_score(y_test, test_preds))\n",
    "            f1_scores.append(f1_score(y_test, test_preds))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fold {i} failed: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(\"No valid backtest folds completed\")\n",
    "    \n",
    "    # Print accuracy statistics\n",
    "    print(\"\\n=== MODEL ACCURACY METRICS ===\")\n",
    "    print(f\"Average Accuracy: {np.mean(accuracy_scores):.2%}\")\n",
    "    print(f\"Average Precision: {np.mean(precision_scores):.2%}\")\n",
    "    print(f\"Average Recall: {np.mean(recall_scores):.2%}\")\n",
    "    print(f\"Average F1 Score: {np.mean(f1_scores):.2%}\")\n",
    "    print(f\"\\nFold-by-fold Accuracy Scores:\")\n",
    "    for i, acc in enumerate(accuracy_scores):\n",
    "        print(f\"Fold {i+1}: {acc:.2%}\")\n",
    "    \n",
    "    return pd.concat(results), models, feature_cols  # Now returning feature_cols too\n",
    "\n",
    "#metric calc\n",
    "def calculate_strategy_metrics(results_df, fee_pct=0.0005):\n",
    "    \"\"\"Enhanced metrics with accuracy reporting\"\"\"\n",
    "    df = results_df.copy()\n",
    "    \n",
    "    # Trading returns\n",
    "    df['Strategy_Return'] = np.where(\n",
    "        df['Prediction'] == 1,\n",
    "        (df['Next_Close'] / df['Close'] - 1) - fee_pct,\n",
    "        0\n",
    "    )\n",
    "    df['BH_Return'] = (df['Next_Close'] / df['Close'] - 1)\n",
    "    \n",
    "    # Cumulative returns\n",
    "    df['Cum_Strategy'] = (1 + df['Strategy_Return']).cumprod()\n",
    "    df['Cum_BH'] = (1 + df['BH_Return']).cumprod()\n",
    "    \n",
    "    # Accuracy metrics\n",
    "    accuracy = (df['Prediction'] == df['Actual']).mean()\n",
    "    precision = (df[(df['Prediction'] == 1) & (df['Actual'] == 1)].shape[0] / \n",
    "                max(1, df[df['Prediction'] == 1].shape[0]))\n",
    "    recall = (df[(df['Prediction'] == 1) & (df['Actual'] == 1)].shape[0] / \n",
    "             max(1, df[df['Actual'] == 1].shape[0]))\n",
    "    \n",
    "    # Risk metrics\n",
    "    sharpe = (df['Strategy_Return'].mean() / df['Strategy_Return'].std()) * np.sqrt(365)\n",
    "    max_dd = (df['Cum_Strategy'].cummax() - df['Cum_Strategy']).max()\n",
    "    \n",
    "    return {\n",
    "        'df': df,\n",
    "        'metrics': {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'max_drawdown': max_dd,\n",
    "            'total_return': df['Cum_Strategy'].iloc[-1],\n",
    "            'bh_return': df['Cum_BH'].iloc[-1],\n",
    "            'win_rate': (df['Strategy_Return'] > 0).mean()\n",
    "        }\n",
    "    }\n",
    "\n",
    "#results ploting\n",
    "def plot_backtest_results(results):\n",
    "    \"\"\"Enhanced visualization with accuracy\"\"\"\n",
    "    df = results['df']\n",
    "    metrics = results['metrics']\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Cumulative Returns\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(df['Date'], df['Cum_Strategy'], label=f'Strategy ({metrics[\"total_return\"]:.2f}x)', linewidth=2)\n",
    "    plt.plot(df['Date'], df['Cum_BH'], label=f'Buy & Hold ({metrics[\"bh_return\"]:.2f}x)', linestyle='--')\n",
    "    plt.title('Strategy Performance')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Drawdown\n",
    "    plt.subplot(3, 1, 2)\n",
    "    drawdown = (df['Cum_Strategy'].cummax() - df['Cum_Strategy'])\n",
    "    plt.fill_between(df['Date'], drawdown, color='red', alpha=0.3)\n",
    "    plt.title(f'Drawdown (Max: {metrics[\"max_drawdown\"]:.2%})')\n",
    "    plt.ylabel('Drawdown')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Prediction Accuracy\n",
    "    plt.subplot(3, 1, 3)\n",
    "    correct = df['Prediction'] == df['Actual']\n",
    "    rolling_acc = correct.rolling(30).mean()\n",
    "    plt.plot(df['Date'], rolling_acc, label='30-day Accuracy', color='green')\n",
    "    plt.axhline(metrics['accuracy'], color='red', linestyle='--', label=f'Overall Accuracy ({metrics[\"accuracy\"]:.2%})')\n",
    "    plt.title('Model Prediction Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print full metrics\n",
    "    print(\"\\n=== COMPREHENSIVE PERFORMANCE METRICS ===\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2%}\")\n",
    "    print(f\"Precision: {metrics['precision']:.2%}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2%}\")\n",
    "    print(f\"Win Rate: {metrics['win_rate']:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"Strategy Return: {metrics['total_return']:.2f}x\")\n",
    "    print(f\"Buy & Hold Return: {metrics['bh_return']:.2f}x\")\n",
    "\n",
    "# main\n",
    "def main():\n",
    "    print(\"=== STARTING PIPELINE ===\")\n",
    "    try:\n",
    "        # === Step 1: Load Data ===\n",
    "        print(\"\\nLoading price data\")\n",
    "        price_data = get_price_data(days=365)\n",
    "        \n",
    "        print(\"\\nLoading sentiment data\")\n",
    "        sentiment_data = load_sentiment_data()\n",
    "\n",
    "        # === Step 2: Feature Engineering ===\n",
    "        features = create_features(price_data, sentiment_data)\n",
    "        print(f\"Generated {len(features)} samples with {len(features.columns)} features each\")\n",
    "\n",
    "        # pd.set_option('display.max_columns', None)\n",
    "        # pd.set_option('display.max_rows', None)\n",
    "        # print(\"\\n=== FULL TRAINING DATA ===\")\n",
    "        # print(features)\n",
    "\n",
    "        # === Step 3: Walk-Forward Backtest ===\n",
    "        print(\"\\nRunning walk-forward backtest...\")\n",
    "        backtest_results, models, feature_cols = walk_forward_train(  # Now receiving feature_cols\n",
    "            features,\n",
    "            initial_train_size=40,\n",
    "            retrain_every=20\n",
    "        )\n",
    "        performance = calculate_strategy_metrics(backtest_results)\n",
    "        \n",
    "        # === Step 4: Analyze Results ===\n",
    "        plot_backtest_results(performance)\n",
    "        \n",
    "        # Show feature importance from last model - using the actual feature_cols used\n",
    "        plt.figure(figsize=(10,4))\n",
    "        pd.Series(models[-1].feature_importances_, index=feature_cols).sort_values().plot.barh()\n",
    "        plt.title('Feature Importance (Latest Model)')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nPipeline completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Pipeline failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
